{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "    Testing Hybrid MPSO-DUN model\n",
    "\"\"\"\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from Hybrid_MPSO_CNN import Hybrid_MPSO_CNN as Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (60000, 28, 28, 1)\n",
      "X_test shape:  (10000, 28, 28, 1)\n",
      "y_train shape:  (60000, 10)\n",
      "y_test shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (MNIST dataset)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1) / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  (28, 28, 1) <class 'tuple'>\n",
      "output_shape:  10 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1]\n",
    "print('input_shape: ', input_shape, type(input_shape))\n",
    "print('output_shape: ', output_shape, type(output_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "[1, 1, 1] [59, 11, 0, 11, 3, 1, 1, 201]\n",
      "WARNING:tensorflow:From c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.8216 - val_loss: 0.0120 - val_accuracy: 0.9240\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 0.9299 - val_loss: 0.0093 - val_accuracy: 0.9404\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9439 - val_loss: 0.0081 - val_accuracy: 0.9475\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9519 - val_loss: 0.0072 - val_accuracy: 0.9541\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9574 - val_loss: 0.0074 - val_accuracy: 0.9520\n",
      "1875/1875 [==============================] - 2s 984us/step - loss: 0.0068 - accuracy: 0.9571\n",
      "[1, 1, 1] [17, 13, 1, 2, 3, 1, 0, 881]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0110 - accuracy: 0.9238 - val_loss: 0.0036 - val_accuracy: 0.9772\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0031 - accuracy: 0.9796 - val_loss: 0.0027 - val_accuracy: 0.9824\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0022 - accuracy: 0.9856 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9886 - val_loss: 0.0024 - val_accuracy: 0.9846\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - accuracy: 0.9913 - val_loss: 0.0021 - val_accuracy: 0.9862\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9907\n",
      "[1, 1, 1] [22, 5, 0, 3, 11, 2, 9, 855]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0589 - accuracy: 0.5354 - val_loss: 0.0396 - val_accuracy: 0.7131\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.7497 - val_loss: 0.0326 - val_accuracy: 0.7666\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.7890 - val_loss: 0.0289 - val_accuracy: 0.7986\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.8093 - val_loss: 0.0263 - val_accuracy: 0.8183\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.8278 - val_loss: 0.0246 - val_accuracy: 0.8295\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0250 - accuracy: 0.8257\n",
      "[1, 1, 1] [32, 9, 0, 5, 13, 4, 2, 763]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.6515 - val_loss: 0.0258 - val_accuracy: 0.8255\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.8409 - val_loss: 0.0196 - val_accuracy: 0.8686\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.8702 - val_loss: 0.0172 - val_accuracy: 0.8854\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.8858 - val_loss: 0.0156 - val_accuracy: 0.8953\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.8946 - val_loss: 0.0159 - val_accuracy: 0.8927\n",
      "1875/1875 [==============================] - 2s 985us/step - loss: 0.0160 - accuracy: 0.8926\n",
      "[1, 1, 1] [35, 13, 0, 4, 9, 1, 3, 237]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.8113 - val_loss: 0.0114 - val_accuracy: 0.9248\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9341 - val_loss: 0.0081 - val_accuracy: 0.9463\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9453 - val_loss: 0.0084 - val_accuracy: 0.9443\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9514 - val_loss: 0.0079 - val_accuracy: 0.9471\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9556 - val_loss: 0.0071 - val_accuracy: 0.9541\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0064 - accuracy: 0.9591\n",
      "[1, 1, 1] [59, 11, 0, 11, 3, 1, 1, 201]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.8219 - val_loss: 0.0128 - val_accuracy: 0.9169\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9258 - val_loss: 0.0106 - val_accuracy: 0.9298\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9421 - val_loss: 0.0082 - val_accuracy: 0.9472\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9517 - val_loss: 0.0078 - val_accuracy: 0.9492\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9552 - val_loss: 0.0073 - val_accuracy: 0.9517\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0063 - accuracy: 0.9598\n",
      "[1, 1, 1] [17, 13, 1, 2, 3, 1, 0, 881]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0115 - accuracy: 0.9216 - val_loss: 0.0038 - val_accuracy: 0.9758\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0034 - accuracy: 0.9785 - val_loss: 0.0037 - val_accuracy: 0.9758\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - accuracy: 0.9851 - val_loss: 0.0025 - val_accuracy: 0.9832\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9891 - val_loss: 0.0020 - val_accuracy: 0.9872\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - accuracy: 0.9914 - val_loss: 0.0020 - val_accuracy: 0.9874\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9915\n",
      "[1, 1, 1] [22, 5, 0, 3, 11, 2, 9, 855]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0628 - accuracy: 0.4969 - val_loss: 0.0459 - val_accuracy: 0.6496\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.7335 - val_loss: 0.0315 - val_accuracy: 0.7790\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.7850 - val_loss: 0.0281 - val_accuracy: 0.8031\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.8184 - val_loss: 0.0250 - val_accuracy: 0.8242\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.8311 - val_loss: 0.0239 - val_accuracy: 0.8324\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0237 - accuracy: 0.8363\n",
      "[1, 1, 1] [32, 9, 0, 5, 13, 4, 2, 763]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.6469 - val_loss: 0.0252 - val_accuracy: 0.8316\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.8550 - val_loss: 0.0185 - val_accuracy: 0.8749\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.8812 - val_loss: 0.0165 - val_accuracy: 0.8876\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.8958 - val_loss: 0.0151 - val_accuracy: 0.8986\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9032 - val_loss: 0.0143 - val_accuracy: 0.9024\n",
      "1875/1875 [==============================] - 2s 990us/step - loss: 0.0138 - accuracy: 0.9086\n",
      "[1, 1, 1] [35, 13, 0, 4, 9, 1, 3, 237]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.8136 - val_loss: 0.0112 - val_accuracy: 0.9256\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9380 - val_loss: 0.0091 - val_accuracy: 0.9393\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9496 - val_loss: 0.0076 - val_accuracy: 0.9497\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9558 - val_loss: 0.0074 - val_accuracy: 0.9505\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9606 - val_loss: 0.0066 - val_accuracy: 0.9560\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0054 - accuracy: 0.9658\n",
      "[1, 1, 1] [59, 11, 0, 11, 3, 1, 1, 201]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.8080 - val_loss: 0.0136 - val_accuracy: 0.9122\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9262 - val_loss: 0.0102 - val_accuracy: 0.9352\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9391 - val_loss: 0.0084 - val_accuracy: 0.9448\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9493 - val_loss: 0.0079 - val_accuracy: 0.9488\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9540 - val_loss: 0.0071 - val_accuracy: 0.9546\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.0064 - accuracy: 0.9596\n",
      "[1, 1, 1] [17, 13, 1, 2, 3, 1, 0, 881]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0155 - accuracy: 0.8916 - val_loss: 0.0036 - val_accuracy: 0.9764\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0032 - accuracy: 0.9799 - val_loss: 0.0029 - val_accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0024 - accuracy: 0.9846 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9890 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9903 - val_loss: 0.0022 - val_accuracy: 0.9855\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9904\n",
      "[1, 1, 1] [22, 5, 0, 3, 11, 2, 9, 855]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0599 - accuracy: 0.5218 - val_loss: 0.0379 - val_accuracy: 0.7336\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.7657 - val_loss: 0.0301 - val_accuracy: 0.7902\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.8080 - val_loss: 0.0257 - val_accuracy: 0.8250\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.8251 - val_loss: 0.0239 - val_accuracy: 0.8351\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.8424 - val_loss: 0.0224 - val_accuracy: 0.8461\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0223 - accuracy: 0.8476\n",
      "[1, 1, 1] [32, 9, 0, 5, 13, 4, 2, 763]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.6579 - val_loss: 0.0243 - val_accuracy: 0.8376\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.8562 - val_loss: 0.0189 - val_accuracy: 0.8717\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.8833 - val_loss: 0.0158 - val_accuracy: 0.8957\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.8992 - val_loss: 0.0145 - val_accuracy: 0.9026\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9076 - val_loss: 0.0138 - val_accuracy: 0.9044\n",
      "1875/1875 [==============================] - 2s 967us/step - loss: 0.0133 - accuracy: 0.9115\n",
      "[1, 1, 1] [35, 13, 0, 4, 9, 1, 3, 237]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.8109 - val_loss: 0.0107 - val_accuracy: 0.9309\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9372 - val_loss: 0.0082 - val_accuracy: 0.9460\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9491 - val_loss: 0.0083 - val_accuracy: 0.9462\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9554 - val_loss: 0.0075 - val_accuracy: 0.9504\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9576 - val_loss: 0.0070 - val_accuracy: 0.9536\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9620\n",
      "[1, 1, 1] [59, 11, 0, 11, 3, 1, 1, 201]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.8251 - val_loss: 0.0120 - val_accuracy: 0.9244\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9293 - val_loss: 0.0099 - val_accuracy: 0.9342\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9419 - val_loss: 0.0086 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9507 - val_loss: 0.0075 - val_accuracy: 0.9513\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9571 - val_loss: 0.0072 - val_accuracy: 0.9542\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0065 - accuracy: 0.9593\n",
      "[1, 1, 1] [17, 13, 1, 2, 3, 1, 0, 881]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0107 - accuracy: 0.9265 - val_loss: 0.0036 - val_accuracy: 0.9778\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0030 - accuracy: 0.9805 - val_loss: 0.0032 - val_accuracy: 0.9787\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0023 - accuracy: 0.9854 - val_loss: 0.0024 - val_accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - accuracy: 0.9892 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9908 - val_loss: 0.0021 - val_accuracy: 0.9868\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 0.9916\n",
      "[1, 1, 1] [22, 5, 0, 3, 11, 2, 9, 855]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0561 - accuracy: 0.5681 - val_loss: 0.0356 - val_accuracy: 0.7492\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.7710 - val_loss: 0.0289 - val_accuracy: 0.7970\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.8104 - val_loss: 0.0252 - val_accuracy: 0.8251\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.8292 - val_loss: 0.0245 - val_accuracy: 0.8302\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.8420 - val_loss: 0.0219 - val_accuracy: 0.8495\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0216 - accuracy: 0.8524\n",
      "[1, 1, 1] [32, 9, 0, 5, 13, 4, 2, 763]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.6527 - val_loss: 0.0231 - val_accuracy: 0.8465\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.8593 - val_loss: 0.0197 - val_accuracy: 0.8677\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.8858 - val_loss: 0.0155 - val_accuracy: 0.8978\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9013 - val_loss: 0.0139 - val_accuracy: 0.9062\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.9084 - val_loss: 0.0137 - val_accuracy: 0.9097\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0132 - accuracy: 0.9136\n",
      "[1, 1, 1] [35, 13, 0, 4, 9, 1, 3, 237]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.8127 - val_loss: 0.0112 - val_accuracy: 0.9249\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9330 - val_loss: 0.0085 - val_accuracy: 0.9445\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9455 - val_loss: 0.0083 - val_accuracy: 0.9460\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9519 - val_loss: 0.0072 - val_accuracy: 0.9524\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9561 - val_loss: 0.0084 - val_accuracy: 0.9448\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0077 - accuracy: 0.9499\n",
      "[1, 1, 1] [59, 11, 0, 11, 3, 1, 1, 201]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.8156 - val_loss: 0.0133 - val_accuracy: 0.9134\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9282 - val_loss: 0.0094 - val_accuracy: 0.9387\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9427 - val_loss: 0.0082 - val_accuracy: 0.9458\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9499 - val_loss: 0.0080 - val_accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9545 - val_loss: 0.0072 - val_accuracy: 0.9524\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0064 - accuracy: 0.9592\n",
      "[1, 1, 1] [17, 13, 1, 2, 3, 1, 0, 881]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0108 - accuracy: 0.9270 - val_loss: 0.0043 - val_accuracy: 0.9719\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0033 - accuracy: 0.9795 - val_loss: 0.0025 - val_accuracy: 0.9846\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0024 - accuracy: 0.9849 - val_loss: 0.0024 - val_accuracy: 0.9843\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9892 - val_loss: 0.0026 - val_accuracy: 0.9824\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9900 - val_loss: 0.0022 - val_accuracy: 0.9859\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0015 - accuracy: 0.9905\n",
      "[1, 1, 1] [22, 5, 0, 3, 11, 2, 9, 855]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.5264 - val_loss: 0.0370 - val_accuracy: 0.7407\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.7601 - val_loss: 0.0288 - val_accuracy: 0.8004\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.7994 - val_loss: 0.0287 - val_accuracy: 0.7993\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0268 - accuracy: 0.8139 - val_loss: 0.0241 - val_accuracy: 0.8338\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.8338 - val_loss: 0.0225 - val_accuracy: 0.8426\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0228 - accuracy: 0.8437\n",
      "[1, 1, 1] [32, 9, 0, 5, 13, 4, 2, 763]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.6335 - val_loss: 0.0249 - val_accuracy: 0.8328\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.8508 - val_loss: 0.0186 - val_accuracy: 0.8749\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.8788 - val_loss: 0.0159 - val_accuracy: 0.8940\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.8925 - val_loss: 0.0147 - val_accuracy: 0.9030\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9025 - val_loss: 0.0143 - val_accuracy: 0.9053\n",
      "1875/1875 [==============================] - 2s 994us/step - loss: 0.0142 - accuracy: 0.9063\n",
      "[1, 1, 1] [35, 13, 0, 4, 9, 1, 3, 237]\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.8214 - val_loss: 0.0104 - val_accuracy: 0.9330\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9404 - val_loss: 0.0081 - val_accuracy: 0.9469\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9510 - val_loss: 0.0071 - val_accuracy: 0.9543\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9556 - val_loss: 0.0065 - val_accuracy: 0.9566\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9591 - val_loss: 0.0063 - val_accuracy: 0.9578\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0052 - accuracy: 0.9664\n",
      "[2, 2, 1] [52, 11, 0, 11, 5, 3, 0, 878]\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'max_pooling2d_25' (type MaxPooling2D).\n    \n    Negative dimension size caused by subtracting 5 from 2 for '{{node sequential_25/max_pooling2d_25/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 5, 5, 1], padding=\"VALID\", strides=[1, 3, 3, 1]](sequential_25/conv2d_25/Relu)' with input shapes: [?,2,2,52].\n    \n    Call arguments received by layer 'max_pooling2d_25' (type MaxPooling2D):\n      • inputs=tf.Tensor(shape=(None, 2, 2, 52), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m hybrid_mpso_cnn \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mHybrid_MPSO_CNN(X_train, y_train, X_test, y_test, input_shape, output_shape)\n\u001b[1;32m----> 2\u001b[0m lvl1_hp, lvl2_hp, fitness \u001b[38;5;241m=\u001b[39m hybrid_mpso_cnn\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m      3\u001b[0m cnn \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mCNN(lvl1_hp, lvl2_hp)\n\u001b[0;32m      4\u001b[0m cnn\u001b[38;5;241m.\u001b[39mbuid_model(input_shape, output_shape)\n",
      "File \u001b[1;32mc:\\Users\\porip\\Documents\\Pouria Ar\\PouriaEdu\\University\\Term7\\Bachlor Project\\Codes\\Hybrid_MPSO_CNN\\Hybrid_MPSO_CNN.py:164\u001b[0m, in \u001b[0;36mHybrid_MPSO_CNN.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 164\u001b[0m     lvl1_hp, lvl2_hp, fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel1_optimize()\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lvl1_hp, lvl2_hp, fitness\n",
      "File \u001b[1;32mc:\\Users\\porip\\Documents\\Pouria Ar\\PouriaEdu\\University\\Term7\\Bachlor Project\\Codes\\Hybrid_MPSO_CNN\\Hybrid_MPSO_CNN.py:134\u001b[0m, in \u001b[0;36mHybrid_MPSO_CNN.level1_optimize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_omega(t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter_lvl1)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, particle_l1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswarm_lvl1):\n\u001b[1;32m--> 134\u001b[0m     particle_l2_gbest, particle_l1\u001b[38;5;241m.\u001b[39mF_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel2_optimize(particle_l1, w)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m particle_l1\u001b[38;5;241m.\u001b[39mF_i \u001b[38;5;241m>\u001b[39m particle_l1\u001b[38;5;241m.\u001b[39mpbest_i_F:\n\u001b[0;32m    136\u001b[0m         particle_l1\u001b[38;5;241m.\u001b[39mpbest_i_F \u001b[38;5;241m=\u001b[39m particle_l1\u001b[38;5;241m.\u001b[39mF_i\n",
      "File \u001b[1;32mc:\\Users\\porip\\Documents\\Pouria Ar\\PouriaEdu\\University\\Term7\\Bachlor Project\\Codes\\Hybrid_MPSO_CNN\\Hybrid_MPSO_CNN.py:152\u001b[0m, in \u001b[0;36mHybrid_MPSO_CNN.level2_optimize\u001b[1;34m(self, particle_l1, w)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(particle_l1\u001b[38;5;241m.\u001b[39mpos_i, particle_l2\u001b[38;5;241m.\u001b[39mpos_ij)\n\u001b[0;32m    151\u001b[0m cnn\u001b[38;5;241m.\u001b[39mbuid_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape)\n\u001b[1;32m--> 152\u001b[0m cnn\u001b[38;5;241m.\u001b[39mtrain_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m    153\u001b[0m particle_l2\u001b[38;5;241m.\u001b[39mF_ij \u001b[38;5;241m=\u001b[39m particle_l2\u001b[38;5;241m.\u001b[39mevaluate(cnn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m particle_l2\u001b[38;5;241m.\u001b[39mF_ij \u001b[38;5;241m>\u001b[39m particle_l2\u001b[38;5;241m.\u001b[39mpbest_ij_F:\n",
      "File \u001b[1;32mc:\\Users\\porip\\Documents\\Pouria Ar\\PouriaEdu\\University\\Term7\\Bachlor Project\\Codes\\Hybrid_MPSO_CNN\\Hybrid_MPSO_CNN.py:212\u001b[0m, in \u001b[0;36mCNN.train_model\u001b[1;34m(self, x_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    209\u001b[0m                        loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    210\u001b[0m                        metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file613chs97.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\porip\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'max_pooling2d_25' (type MaxPooling2D).\n    \n    Negative dimension size caused by subtracting 5 from 2 for '{{node sequential_25/max_pooling2d_25/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 5, 5, 1], padding=\"VALID\", strides=[1, 3, 3, 1]](sequential_25/conv2d_25/Relu)' with input shapes: [?,2,2,52].\n    \n    Call arguments received by layer 'max_pooling2d_25' (type MaxPooling2D):\n      • inputs=tf.Tensor(shape=(None, 2, 2, 52), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hybrid_mpso_cnn = Model.Hybrid_MPSO_CNN(X_train, y_train, X_test, y_test, input_shape, output_shape)\n",
    "lvl1_hp, lvl2_hp, fitness = hybrid_mpso_cnn.run()\n",
    "cnn = Model.CNN(lvl1_hp, lvl2_hp)\n",
    "cnn.buid_model(input_shape, output_shape)\n",
    "cnn.train_model(X_train, y_train, epochs=20, batch_size=64)\n",
    "test_loss, test_acc = cnn.fitness(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
